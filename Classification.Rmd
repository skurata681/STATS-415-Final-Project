---
title: "Classification"
author: "Sarah Kurata"
date: "3/27/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(readr)
library(dplyr)
library(tidyverse)

#libraries for subset methods
library(SignifReg)
library(leaps)

#shrinkage methods
library(glmnet)
library(pls)
library(lares)
#LDA and QDA model
library(MASS)

#Tree library
library(tree)
#RandomForest
library(randomForest)
#gradient boosting
library(gbm)

#support vector classifier
library(e1071)

#KNN library
library(FNN)
```

## Clean data and split into training and test subsets

```{r}
df = read.csv('./Data/full_data.csv')
```


## Testing "on special diet?" as response (DRQSDIET)

### Data cleaning

```{r Classification Test and Training Data}
#CREATING THE TEST AND TRAINING DATA

#first take out NA's in data frame we will use
data_diet <-drop_na(data, DRQSDIET, BMIWT, LBXTC, BPXSY1, DR1_330Z, DR1TCAFF)

#first split in test and train for whole data frame
train_idx <- sample(1:nrow(data_diet), size = floor(.7 * nrow(data_diet)))

#test and training data
train_data <- data_diet[train_idx, ]
test_data <- data_diet[-train_idx, ]

#change to factor for test data
test_data<-filter(test_data, DRQSDIET != 9)
test_data$DRQSDIET01 <- ifelse(test_data$DRQSDIET == 2, 1, 0)

#change to factor for training data
train_data<-filter(train_data, DRQSDIET != 9)
train_data$DRQSDIET01 <- ifelse(train_data$DRQSDIET == 2, 1, 0)
```


```{r KNN}
#SCALE FOR KNN
#calculate mean and sd
mean_train <- colMeans(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')])
sd_train <- sqrt(diag(var(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')])))
#scale the training and test data
X_train_scaled <- scale(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')], center = mean_train, scale = sd_train)
X_test_scaled <- scale(test_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')], center = mean_train, scale = sd_train)


# Cross validation to find optimal K
Ks <- seq(1, 30, by = 1)

#vectors to store the MSEs
trainMSEs <- c()
testMSEs <- c() 

for(K in Ks) {
knnTrain <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_train_scaled, k = K)
knnTest <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_test_scaled, k = K)

trainMSE <- mean(knnTrain != train_data$DRQSDIET)
testMSE <- mean(knnTest != test_data$DRQSDIET)

trainMSEs <- c(trainMSEs, trainMSE)
testMSEs <- c(testMSEs, testMSE)
}
#plot the train and test errors against the K value
plot(Ks, trainMSEs, type = "b", lwd = 2, col = "blue", xlab = "K", ylab = "MSE", ylim = c(0,.4))
lines(Ks, testMSEs, type = "b", lwd = 2, col = "red")
legend("bottomright", legend = c("Train MSE", "Test MSE"), col = c("blue", "red"), lwd = c(2,2))

#which K produces the minimum for testMSEs
x = Ks[which.min(testMSEs)]

#KNN with this ideal K
KNN_11<-knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_test_scaled, k = x)
#test error
mean(KNN_11 != test_data$DRQSDIET)
#confusion matrix
table(KNN_11, test_data$DRQSDIET)
```


```{r AdaBoost}

#Adaboost
#make adaboost model (boosted tree)
adaboost_mod <- gbm(
DRQSDIET01~ BMIWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF, 
data=train_data,
distribution="adaboost",
n.trees=1000)

#variable importance plot
summary(adaboost_mod)

#find test error
adaboost_test_probs <- predict(adaboost_mod, test_data, n.trees=1000, type='response')
adaboost_test_preds <- ifelse(adaboost_test_probs > 0.5, 1, 0)
test_err <- mean(adaboost_test_preds != test_data$DRQSDIET01)
print(test_err)
```


```{r SVM Classifier}
#data cleaning only for svm classifier
train_data$DRQSDIET01 <- as.factor(train_data$DRQSDIET01)
test_data$DRQSDIET01 <- as.factor(test_data$DRQSDIET01)
data_diet$DRQSDIET01 <- ifelse(data_diet$DRQSDIET == 2, 1, 0) 
data_diet$DRQSDIET01 <- as.factor(data_diet$DRQSDIET01)

#subset for only columns needed
train_data <- train_data[, c("DRQSDIET01", "BMXWT", "LBXTC", "BPXSY1", "DR1_330Z", "DR1TCAFF")]
test_data <- test_data[, c("DRQSDIET01", "BMXWT", "LBXTC", "BPXSY1", "DR1_330Z", "DR1TCAFF")]
data_diet <- data_diet[, c("DRQSDIET01", "BMXWT", "LBXTC", "BPXSY1", "DR1_330Z", "DR1TCAFF")]

#for cross validation
test_idx2 <- sample(test_idx, size=round(length(test_idx)/2))
validation_idx <- as.integer(setdiff(test_idx, test_idx2)
                             )
#function to evaluate cost for cross validation
test_cost <- function(p, test_data, vector) {
 svmfit <- svm(DRQSDIET01 ~ BMXWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF,
 data=train_data, # Training data set
 kernel="radial", # Kernel type
 cost=p, # Cost of misclassification
 scale=TRUE)
 preds <- predict(svmfit, na.omit(test_data))
 mean(preds != na.omit(vector))}

#run cross validation to find ideal cost value
validation_errors <- sapply(c(0.001, 0.01, 0.1, 1, 5, 10, 100),
                            FUN=function(p) test_cost(p, data_diet[validation_idx,], 
                            data_diet$DRQSDIET01[validation_idx]))
test_errors <- sapply(c(0.001, 0.01, 0.1, 1, 5, 10, 100),
                      FUN=function(p) test_cost(p, data_diet[test_idx2,], 
                      data_diet$DRQSDIET01[test_idx2]))
all_errors <- c(validation_errors, test_errors)

#plot different cost results
plot(
c(0.001, 0.01, 0.1, 1, 5, 10, 100),
validation_errors,
type="l",
xlab="Cost Values",
ylab="rMSE",
main="Cost Values vs. Test rMSE",
ylim=c(min(all_errors), max(all_errors)))
lines(c(0.001, 0.01, 0.1, 1, 5, 10, 100),
test_errors, col=2)
abline(v=3, lty=3)
legend("topright", legend=c("Validation", "Test"), col=1:2, lty=1)

#ideal cost value is 10 so run svm with cost = 10
svmfit <- svm(DRQSDIET01 ~ BMXWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF,
data=train_data,
kernel="radial",
cost=10, 
scale=TRUE)

#test error
preds <- predict(svmfit, test_data)
mean(preds != test_data$DRQSDIET01)

#can see differences between fitted values and actual
table(svmfit$fitted)
table(test_data$DRQSDIET01)
```