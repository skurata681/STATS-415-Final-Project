---
title: "STATS 415 Final Project"
author: "Sarah Kurata, Hannah Daane, Saman Verma"
date: "3/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#for repreduciability
set.seed(245)

library(haven)
library(readr)
library(dplyr)
library(tidyverse)

#libraries for subset methods
library(SignifReg)
library(leaps)
#shrinkage methods
library(glmnet)
library(pls)
library(lares)
#LDA and QDA model
library(MASS)

#Tree library
library(tree)
#RandomForest
library(randomForest)
#gradient boosting
library(gbm)

#support vector classifier
library(e1071)

#neural network
library(keras)
library(neuralnet)

#KNN library
library(FNN)
```

## Reading in Data

```{r, echo=FALSE}
#2009
bmx09 <- read_xpt("Data/2009/BMX_F.XPT")
bpx09 <- read_xpt("Data/2009/BPX_F.XPT")
demo09 <- read_xpt("Data/2009/DEMO_F.XPT")
dr109 <- read_xpt("Data/2009/DR1TOT_F.XPT")
smq09 <- read_xpt("Data/2009/SMQ_F.XPT")
tchol09 <- read_xpt("Data/2009/TCHOL_F.XPT")

data09 = merge(bmx09, bpx09, by = "SEQN", all.x = TRUE)
listy = list(demo09, dr109, smq09, tchol09)
for(i in 1:4){
  data09 = merge(data09, listy[[i]], by = "SEQN", all.x = TRUE)
}
write_csv(data09, "Data/2009/data2009.csv")

#2011
bmx11 <- read_xpt("Data/2011/BMX_G.XPT")
bpx11 <- read_xpt("Data/2011/BPX_G.XPT")
demo11 <- read_xpt("Data/2011/DEMO_G.XPT")
dr111 <- read_xpt("Data/2011/DR1TOT_G.XPT")
smq11 <- read_xpt("Data/2011/SMQ_G.XPT")
tchol11 <- read_xpt("Data/2011/TCHOL_G.XPT")

data11 = merge(bmx11, bpx11, by = "SEQN", all.x = TRUE)
listy = list(demo11, dr111, smq11, tchol11)
for(i in 1:4){
  data11 = merge(data11, listy[[i]], by = "SEQN", all.x = TRUE)
}
write_csv(data11, "Data/2011/data2011.csv")

#2013
bmx13 <- read_xpt("Data/2013/BMX_H.XPT")
bpx13 <- read_xpt("Data/2013/BPX_H.XPT")
demo13 <- read_xpt("Data/2013/DEMO_H.XPT")
dr113 <- read_xpt("Data/2013/DR1TOT_H.XPT")
smq13 <- read_xpt("Data/2013/SMQ_H.XPT")
tchol13 <- read_xpt("Data/2013/TCHOL_H.XPT")

data13 = merge(bmx13, bpx13, by = "SEQN", all.x = TRUE)
listy = list(demo13, dr113, smq13, tchol13)
for(i in 1:4){
  data13 = merge(data13, listy[[i]], by = "SEQN", all.x = TRUE)
}
write_csv(data13, "Data/2013/data2013.csv")

#2015
bmx15 <- read_xpt("Data/2015/BMX_I.XPT")
bpx15 <- read_xpt("Data/2015/BPX_I.XPT")
demo15 <- read_xpt("Data/2015/DEMO_I.XPT")
dr115 <- read_xpt("Data/2015/DR1TOT_I.XPT")
smq15 <- read_xpt("Data/2015/SMQ_I.XPT")
tchol15 <- read_xpt("Data/2015/TCHOL_I.XPT")

data15 = merge(bmx15, bpx15, by = "SEQN", all.x = TRUE)
listy = list(demo15, dr115, smq15, tchol15)
for(i in 1:4){
  data15 = merge(data15, listy[[i]], by = "SEQN", all.x = TRUE)
}
write_csv(data15, "Data/2015/data2015.csv")

#2017
bmx17 <- read_xpt("Data/2017/BMX_J.XPT")
bpx17 <- read_xpt("Data/2017/BPX_J.XPT")
demo17 <- read_xpt("Data/2017/DEMO_J.XPT")
dr117 <- read_xpt("Data/2017/DR1TOT_J.XPT")
smq17 <- read_xpt("Data/2017/SMQ_J.XPT")
tchol17 <- read_xpt("Data/2017/TCHOL_J.XPT")

data17 = merge(bmx17, bpx17, by = "SEQN", all.x = TRUE)
listy = list(demo17, dr117, smq17, tchol17)
for(i in 1:4){
  data17 = merge(data17, listy[[i]], by = "SEQN", all.x = TRUE)
}
write_csv(data17, "Data/2017/data2017.csv")

#Total
data = bind_rows(data09,data11)
listy = list(data13,data15,data17)
for(i in 1:3){
  data = bind_rows(data, listy[[i]])
}
write_csv(data,"Data/full_data.csv")

train = read_csv("Data/Kaggle/train.csv")
train = merge(train, data, by = "SEQN", all.x = TRUE)
train=train[, colSums(is.na(train))==0]
train = train[, -which(names(train)%in%c("SMDUPCA", "SMD100BR", "DR1DRSTZ", "DRABF", "RIDSTATR"))]
write_csv(train, "Data/Total/train.csv")
test = read_csv("Data/Kaggle/test.csv")
test = merge(test, data, by = "SEQN", all.x = TRUE)
test=test[, colSums(is.na(test))==0]
test = test[, -which(names(test)%in%c("SMDUPCA", "SMD100BR", "DR1DRSTZ", "DRABF", "RIDSTATR"))]
drops = c(setdiff(names(test), names(train)))
test = test[,!(names(test) %in% drops)]
write_csv(test, "Data/Total/test.csv")
```


```{r}
#original attempt
view(train)
model1 = glm(y ~ BMDSTATS, data = train)
x = predict(model1, newdata = test)
firstprediction = data.frame(test$SEQN, x)
firstprediction <-  firstprediction%>%rename(SEQN=test.SEQN)
firstprediction<-  firstprediction%>%rename(y=x)
write_csv(firstprediction, "Predictions/Kaggle/firstPrediction.csv")

#KAGGLE ATTEMPTS. TRIED BACKWARD AND FORWARD SELECTION WITH REGSUBSETS
    #LOO-CV
    # n_predictors <- ncol(train) - 1
    # regfit.full <- regsubsets(y ~ ., data = train, nvmax = n_predictors, method = "backward")
    # reg.summary <- summary(regfit.full)
    # reg.summary$rsq
#BY RUNNING BACKWARDS AND FORWARD SELECTION WE GOT LOW RSQ VALUE OF APPROXIMATELY .32

#KAGGLE ATTEMPTS FORWARD SELECTION, this method looks at p-values
nullmodel <- lm(y ~ 1, data = non_correlated)
fullmodel <- lm(y ~ ., data = non_correlated)
select.p.fwd <- SignifReg(fit = nullmodel,
scope = list(lower = formula(nullmodel), upper = formula(fullmodel)),
alpha = 0.05, direction = "forward",
adjust.method = "none", trace = FALSE)
summary(select.p.fwd)

#resulting model from p-value
forward_selection_model_signifreg <-lm(formula = y ~ SMAQUEX2 + BMXARML + DMDBORN4 + BPXSY1 + BPACSZ + DR1TSUGR + DR1TFIBE + RIDAGEYR + DR1TKCAL + BMXWT + BMXBMI + BMXHT + BMXWAIST + RIDEXMON + BMXARMC + SIAPROXY + DR1TATOC + FIALANG + DR1TS100 + SEQN + LBXTC + SIAINTRP + WTINT2YR, data = train)
summary(forward_selection_model_signifreg)

#check model diagnostics of forward selection model
ggplot() + geom_point(mapping = aes(x = fitted(forward_selection_model_signifreg), residuals(forward_selection_model_signifreg))) + geom_hline(yintercept = 0) + xlab("Fitted values") + ylab("Residuals")

#normal qq plot shows that the distribution is longtailed, cauchy. this is concerning for least squares
qqnorm(forward_selection_model_signifreg$residuals, ylab = "Residuals")
qqline(forward_selection_model_signifreg$residuals)

#tried to take out values very correlated so backward selection would run
myvars <- names(train) %in% c("LBXTC", "WTINT2YR","DR1TPFAT", "DR1TMFAT", "DR1TFOLA", "DR1TSFAT")
non_correlated<-train[!myvars]
cor(train)[cor(train)>.9999 & cor(train)<1]
#FOUND HIGHLY CORRELATED VALUES, seeing which values are highly correlated 
corr_cross(non_correlated, 
  max_pvalue = 0.05, 
  top = 10
)
#attempting backward selection
nullmodel <- lm(y ~ 1, data = non_correlated)
fullmodel <- lm(y ~ ., data = non_correlated)
select.p.fwd <- SignifReg(fit = fullmodel,
scope = list(lower = formula(nullmodel), upper = formula(fullmodel)),
alpha = 0.05, direction = "backward",
adjust.method = "none", trace = FALSE)
summary(select.p.fwd)

#FOUND NO NON LINEAR RELATIONSHIPS BETWEEN ALL PREDICTORS AND RESPONSE

#For the long tailed distribution can try a transformation of the response variable (log, sqrt). Also use robust methods such as huber's method
#in order to generate R^2 for some models generate predictions and look at squared correlation
#Neural Networks will most likely work well

#attempt huber method because long-tailed distribution
huber_method<-rlm(formula = y ~ SMAQUEX2 + BMXARML + DMDBORN4 + BPXSY1 + BPACSZ + DR1TSUGR + DR1TFIBE + RIDAGEYR + DR1TKCAL + BMXWT + BMXBMI + BMXHT + BMXWAIST + RIDEXMON + BMXARMC + SIAPROXY + DR1TATOC + FIALANG + DR1TS100 + SEQN + LBXTC + SIAINTRP + WTINT2YR, data = train)
#predict for huber method
predictions_test<-predict(huber_method, newdata=test)
#R^squared for hubers method
(cor(predictions_test,test$y)^2)

#Random Forest Model  
randomForest(y ~., data = train, mtry = 48, importance = TRUE)

#PCR does not perform as well as Random Forest
summary(pcr(y~., data=train, scale = TRUE, validation = "CV"))

#PLSR performs very similarly to PCR
summary(plsr(y~., data=train, scale = TRUE, validation = "CV"))

#Attempt at Neural Network, to be tried and dealt with later
neuralnetmodel<-neuralnet(y ~ ., train, hidden = 4500)
predict_testNN = compute(neuralnetmodel, test)
cor(predict_testNN$net.result,train$y[1:3823])^2
```


```{r}
#Caffeine
library(Hmisc)
library(corrplot)
correlationmatrix = cor(train[,c(which( colnames(train)=="DRD340" ), which( colnames(train)=="DRD350A" ), which( colnames(train)=="DRD350B" ), which( colnames(train)=="DRD350C" ), which( colnames(train)=="DRD350D" ), which( colnames(train)=="DRD350E" ))])
corrplot(correlationmatrix)
palette = colorRampPalette(c("green", "white", "red")) (20)
heatmap(x = correlationmatrix, col = palette, symm = TRUE)
cor(train$DR1_330Z, train[1:100])
```


```{r}
library(data.table)
library(tidyr)
classification = copy(data)
classification = classification %>% drop_na("SMQ905")
classification = classification %>% drop_na("SMD641")
classification = classification %>% drop_na("DR1TALCO")
correlationmatrix = cor(classification[,c(which( colnames(classification)=="SMQ905" ), which( colnames(classification)=="SMD641" ), which( colnames(classification)=="DR1TALCO" ))])
corrplot(correlationmatrix)
palette = colorRampPalette(c("green", "white", "red")) (20)
heatmap(x = correlationmatrix, col = palette, symm = TRUE)
```


```{r}
#ridageyr, WTINT2YR  ,WTMEC2YR, DR1TVB2 , DR1TPOTA, DR1TMOIS   
data_e_cig<-mutate(data,E_Cig = case_when(
  SMQ905 <= 9 ~ "Never",
  SMQ905 <= 19 ~ "Rarely",
  SMQ905 <= 29 ~ "Sometimes",
  SMQ905 <= 39 ~ "Always",
))

#count of each category
table(data_e_cig$E_Cig)
prop.table(table(data_e_cig$E_Cig))
#make sure all data is omitted
na.omit(data_e_cig$E_Cig)

#create training and test set based on amount of each category
data_never = which(data_e_cig$E_Cig == "Never")
data_rarely = which(data_e_cig$E_Cig == "Rarely")
data_sometimes = which(data_e_cig$E_Cig == "Sometimes")
data_always = which(data_e_cig$E_Cig == "Always")
#training and test data
train_id = c(sample(data_never, size = trunc(0.70 * length(data_never))),
sample(data_rarely, size = trunc(0.70 * length(data_rarely))),
sample(data_sometimes, size = trunc(0.70 * length(data_sometimes))),
sample(data_always, size = trunc(0.70 * length(data_always))))
data_new_train = data_e_cig[train_id, ]
data_new_test = data_e_cig[-train_id, ]


#quick lda
lda_e_cig<-lda(E_Cig~ SMQ670, data=data_new_train)

#attempting to find train and test error, something is wrong with code
# predict(lda_e_cig, data_new_train)$class
# e_cig_lda_test_pred = predict(lda_e_cig, data_new_test)$class
# 
# train_err = mean(e_cig_lda_train_pred != data_new_train$E_Cig)
# test_err = mean(e_cig_lda_test_pred != data_new_test$E_Cig)
# train_err
# test_err
```


```{r CLASSIFICATION}
two_way = table(data_e_cig$E_Cig, data_e_cig$RIAGENDR)
prop.table(two_way)
prop.table(two_way,1)
prop.table(two_way,2)

#according to chi-squared test gender is significant, gender variable
e_cig <-table(data_e_cig$E_Cig, data_e_cig$RIAGENDR)
chisq.test(e_cig, correct=FALSE)

#highly related but such small value may be incorrect, tried to quit smoking variable
e_cig <-table(data_e_cig$E_Cig, data_e_cig$SMQ670)
chisq.test(e_cig, correct=FALSE)

#also highly related; do you now smoke cigarettes variable, issue with size
e_cig <-table(data_e_cig$E_Cig, data_e_cig$SMQ935)
chisq.test(e_cig, correct=FALSE)

#decently related ish, race/hispanic origin, same issue with size
e_cig <-table(data_e_cig$E_Cig, data_e_cig$RIDRETH1)
chisq.test(e_cig, correct=FALSE)

#decently related, same issue with size, # of children 5 years or younger in HH
e_cig <-table(data_e_cig$E_Cig, data_e_cig$DMDHHSZA)
chisq.test(e_cig, correct=FALSE)

#decently related, same issue with size, annual household income
e_cig <-table(data_e_cig$E_Cig, data_e_cig$INDHHIN2)
chisq.test(e_cig, correct=FALSE)
```

```{r Classification Test and Training Data}
#CREATING THE TEST AND TRAINING DATA


#first take out NA's in data frame we will use
data_diet <-drop_na(data, DRQSDIET, BMIWT, LBXTC, BPXSY1, DR1_330Z, DR1TCAFF)

#first split in test and train for whole data frame
train_idx <- sample(1:nrow(data_diet), size = floor(.7 * nrow(data_diet)))

#test and training data
train_data <- data_diet[train_idx, ]
test_data <- data_diet[-train_idx, ]

#change to factor for test data
test_data<-filter(test_data, DRQSDIET != 9)
test_data$DRQSDIET01 <- ifelse(test_data$DRQSDIET == 2, 1, 0)

#change to factor for training data
train_data<-filter(train_data, DRQSDIET != 9)
train_data$DRQSDIET01 <- ifelse(train_data$DRQSDIET == 2, 1, 0)
```

```{r Knn for Classification}
#SCALE FOR KNN
#calculate mean and sd
mean_train <- colMeans(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')])
sd_train <- sqrt(diag(var(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')])))
#scale the training and test data
X_train_scaled <- scale(train_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')], center = mean_train, scale = sd_train)
X_test_scaled <- scale(test_data[c('BMIWT','LBXTC', 'BPXSY1', 'DR1_330Z', 'DR1TCAFF')], center = mean_train, scale = sd_train)


#run cross validation in order to find ideal K on training set
Ks <- seq(1, 352, by = 10)

#vectors to store the MSEs
trainMSEs <- c()
testMSEs <- c() 

for(K in Ks) {
knnTrain <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_train_scaled, k = K)
knnTest <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_test_scaled, k = K)

trainMSE <- mean(knnTrain != train_data$DRQSDIET)
testMSE <- mean(knnTest != test_data$DRQSDIET)

trainMSEs <- c(trainMSEs, trainMSE)
testMSEs <- c(testMSEs, testMSE)
}
#plot the train and test errors against the K value
plot(Ks, trainMSEs, type = "b", lwd = 2, col = "blue",
xlab = "K", ylab = "MSE")
lines(Ks, testMSEs, type = "b", lwd = 2, col = "red")
legend("bottomright", legend = c("Train MSE", "Test MSE"), col = c("blue", "red"), lwd = c(2,2))

#MUCH SMALLER SEQUENCE
Ks <- seq(1, 40, by = 1)

#vectors to store the MSEs
trainMSEs <- c()
testMSEs <- c() 

for(K in Ks) {
knnTrain <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_train_scaled, k = K)
knnTest <- knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_test_scaled, k = K)

trainMSE <- mean(knnTrain != train_data$DRQSDIET)
testMSE <- mean(knnTest != test_data$DRQSDIET)

trainMSEs <- c(trainMSEs, trainMSE)
testMSEs <- c(testMSEs, testMSE)
}
#plot the train and test errors against the K value
plot(Ks, trainMSEs, type = "b", lwd = 2, col = "blue", xlab = "K", ylab = "MSE", ylim = c(0,.4))
lines(Ks, testMSEs, type = "b", lwd = 2, col = "red")
legend("bottomright", legend = c("Train MSE", "Test MSE"), col = c("blue", "red"), lwd = c(2,2))

#which K produces the minimum for testMSEs
x = Ks[which.min(testMSEs)]

#KNN with this ideal K
KNN_11<-knn(train = X_train_scaled, cl = train_data$DRQSDIET,
test = X_test_scaled, k = x)
#test error
mean(KNN_11 != test_data$DRQSDIET)
#confusion matrix
table(KNN_11, test_data$DRQSDIET)
```


```{r Decision Trees/Adaboost for Classification Problem}
#General Classification Tree
tree_model=tree(factor(DRQSDIET01)~BMIWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF, train_data)
tree_preds =predict(tree_model, test_data, type = "class")
test_err <- mean(test_preds != test_data$DRQSDIET01)
print(test_err)

#prune the model
cv_tree = cv.tree(tree_model,FUN=prune.misclass)
par(mfrow=c(1,2))
plot(cv_tree$size,cv_tree$dev / length(train_data),ylab="cv error", xlab="size",type="b")
plot(cv_tree$k, cv_tree$dev / length(train),ylab="cv error", xlab="k",type="b")

#test error for pruned data
prune_model=prune.misclass(tree_model,best=5)
tree_preds_pruned =predict(prune_model, test_data, type = "class")
(test_err_pruned <- mean(tree_preds_pruned != test_data$DRQSDIET01))

#confusion matrix
table(tree_preds_pruned, test_data$DRQSDIET01)

#decision tree for pruned data
plot(prune_model)
text(prune_model,pretty=0)




#Adaboost
#make adaboost model (boosted tree)
adaboost_mod <- gbm(
DRQSDIET01~ BMIWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF, 
data=train_data,
distribution="adaboost",
n.trees=1000)

#variable importance plot
summary(adaboost_mod)

#find test error
adaboost_test_probs <- predict(adaboost_mod, test_data, n.trees=1000, type='response')
adaboost_test_preds <- ifelse(adaboost_test_probs > 0.5, 1, 0)
test_err <- mean(adaboost_test_preds != test_data$DRQSDIET01)
print(test_err)
```
So far it appears that KNN is performing better than Adaboost in terms of test error.

```{r QDA for Classification Problem}
#make qda model
qda_model = qda(DRQSDIET01~ BMIWT + LBXTC + BPXSY1 + DR1_330Z + DR1TCAFF, 
data=train_data)

#training and test error
train_predictions= predict(qda_model, train_data)$class
test_predictions = predict(qda_model, test_data)$class
train_err = mean(train_predictions != train_data$DRQSDIET01)
test_err = mean(test_predictions != test_data$DRQSDIET01)
test_err
```


```{r EDA for DRQSDIET}
data <-filter(data, DRQSDIET != 9)
table(data$DRQSDIET)

boxplot(BPXSY1~DRQSDIET, data = data)
```